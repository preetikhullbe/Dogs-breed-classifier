{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18yHpbuAgg7J-x3_qZLYyRIvgRD3QtNMT",
      "authorship_tag": "ABX9TyOMfLfqjQOv8EFRuvDFdIGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetikhullbe/Dogs-breed-classifier/blob/main/Dogs_breed_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH9Vm_z-hAjE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlMcn88R6kkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os"
      ],
      "metadata": {
        "id": "RPPUNqIVKUU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio"
      ],
      "metadata": {
        "id": "5ShrMhDPajff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "4g2jx27UkL8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# prompt: print some images from the folder dir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import imageio as iio\n",
        "from PIL import Image\n",
        "import os\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "76O4dOW5nXpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required module\n",
        "from pathlib import Path\n",
        "\n",
        "# get the path/directory\n",
        "# get the path/directory\n",
        "base_dir = \"/content/drive/MyDrive/dataset\"\n",
        "\n",
        "# iterate over files in\n",
        "# that directory\n",
        "images = Path(base_dir).glob('*.png')\n",
        "for image in images:\n",
        "    print(image)"
      ],
      "metadata": {
        "id": "-xpLzYC8wFYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the directory\n",
        "images_list = os.listdir(base_dir)\n",
        "\n",
        "# Filter out non-image files (optional)\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "images_list = [img for img in images_list if img.lower().endswith(valid_extensions)]\n",
        "\n",
        "# Function to display images\n",
        "def display_images(images_list, base_dir, num_images=5):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    for i, img_name in enumerate(images_list[:num_images]):\n",
        "        img_path = os.path.join(base_dir, img_name)\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(img_name)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "24w-p8LeclRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 images\n",
        "display_images(images_list, base_dir, num_images=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NkrIaK80gCre",
        "outputId": "2fc53b0f-c1ed-4554-ce07-507b13615b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKtt02-BiMvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory paths\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Create the directories\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "\n",
        "# If you have multiple classes, create subdirectories for each class\n",
        "classes = ['Yorkshire_Terrier', 'Rottweiler','Poodle','Labrador_Retriever','Golden_Retriever',\n",
        "     'German_Shepherd','Dachshund','BullDog','Boxer','Beagle']\n",
        "     # Add your classes here\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_dir, class_name), exist_ok=True)\n",
        "\n",
        "print(\"Directories created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vInJw3MiLAW",
        "outputId": "390f64bf-289a-4724-d180-0636850f68bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories created successfully!\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "\n",
        "# Get the list of all images\n",
        "# Check the glob pattern and base_dir to ensure they are correct\n",
        "all_images = glob.glob(os.path.join(base_dir, '**/*.[jp][pn]g'), recursive=True)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_images, validation_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to copy images to the target directory\n",
        "def copy_images(image_list, target_dir):\n",
        "    for image_path in image_list:\n",
        "        class_name = os.path.basename(image_path).split('_')[0]  # Assuming class name is part of the file name\n",
        "        target_class_dir = os.path.join(target_dir, class_name)\n",
        "        shutil.copy(image_path, target_class_dir)\n",
        "\n",
        "# Copy training images\n",
        "copy_images(train_images, train_dir)\n",
        "\n",
        "# Copy validation images\n",
        "copy_images(validation_images, validation_dir)\n",
        "\n",
        "print(\"Data split and copied successfully!\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8x6jjkMt7n1",
        "outputId": "128ce754-37cf-4d03-c434-e76aadda4361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split and copied successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data Augmentation and Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "tpnMk7C647Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Use 'categorical' for multi-class classification\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Use 'categorical' for multi-class classification\n",
        ")"
      ],
      "metadata": {
        "id": "n1dLWdBh5mwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d5773c-ac28-44dd-c954-8d8240783740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 393 images belonging to 10 classes.\n",
            "Found 92 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Building the CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(classes), activation='softmax')  # Use 'softmax' for multi-class classification\n",
        "])\n"
      ],
      "metadata": {
        "id": "fQY6XbSo5vvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for multi-class classification\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "-GY24yz555Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "7vKmNyMf58gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15394c51-8371-4748-897b-e3517fdf6818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               3211776   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3457738 (13.19 MB)\n",
            "Trainable params: 3457738 (13.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Training the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "kT6yRnnE6FLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aead849-707c-46e6-bf52-c236175c6b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 31s 2s/step - loss: 1.9862 - accuracy: 0.2355 - val_loss: 1.7127 - val_accuracy: 0.1719\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 25s 2s/step - loss: 1.7572 - accuracy: 0.1856 - val_loss: 1.6902 - val_accuracy: 0.0781\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.7643 - accuracy: 0.2022 - val_loss: 1.6970 - val_accuracy: 0.2031\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.6785 - accuracy: 0.2382 - val_loss: 1.6516 - val_accuracy: 0.1250\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 26s 2s/step - loss: 1.6760 - accuracy: 0.2355 - val_loss: 1.6216 - val_accuracy: 0.1719\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.6405 - accuracy: 0.2604 - val_loss: 1.6022 - val_accuracy: 0.2344\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.6608 - accuracy: 0.2216 - val_loss: 1.5829 - val_accuracy: 0.2344\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.6101 - accuracy: 0.2715 - val_loss: 1.5317 - val_accuracy: 0.2969\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.6225 - accuracy: 0.2382 - val_loss: 1.5768 - val_accuracy: 0.2344\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.5645 - accuracy: 0.3229 - val_loss: 1.5328 - val_accuracy: 0.2969\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.5308 - accuracy: 0.3435 - val_loss: 1.5482 - val_accuracy: 0.2812\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 27s 2s/step - loss: 1.5569 - accuracy: 0.2812 - val_loss: 1.4532 - val_accuracy: 0.3438\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.5139 - accuracy: 0.2881 - val_loss: 1.4243 - val_accuracy: 0.3750\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.5350 - accuracy: 0.2917 - val_loss: 1.4393 - val_accuracy: 0.4375\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 25s 2s/step - loss: 1.4676 - accuracy: 0.3684 - val_loss: 1.2956 - val_accuracy: 0.5469\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.4488 - accuracy: 0.3795 - val_loss: 1.3374 - val_accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 26s 2s/step - loss: 1.4573 - accuracy: 0.3573 - val_loss: 1.3191 - val_accuracy: 0.4219\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.4763 - accuracy: 0.3712 - val_loss: 1.3604 - val_accuracy: 0.3906\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.4042 - accuracy: 0.3435 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 28s 2s/step - loss: 1.3965 - accuracy: 0.4044 - val_loss: 1.2315 - val_accuracy: 0.4688\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 26s 2s/step - loss: 1.3677 - accuracy: 0.4127 - val_loss: 1.4673 - val_accuracy: 0.3438\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.3932 - accuracy: 0.4100 - val_loss: 1.2618 - val_accuracy: 0.5000\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 25s 2s/step - loss: 1.3799 - accuracy: 0.3961 - val_loss: 1.2301 - val_accuracy: 0.5000\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 25s 2s/step - loss: 1.3208 - accuracy: 0.4515 - val_loss: 1.2074 - val_accuracy: 0.4531\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.3027 - accuracy: 0.4349 - val_loss: 1.1741 - val_accuracy: 0.5625\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.2824 - accuracy: 0.4432 - val_loss: 1.1310 - val_accuracy: 0.5938\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 25s 2s/step - loss: 1.2534 - accuracy: 0.4931 - val_loss: 1.0875 - val_accuracy: 0.6094\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.2406 - accuracy: 0.4598 - val_loss: 1.1229 - val_accuracy: 0.6094\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 25s 2s/step - loss: 1.1792 - accuracy: 0.5402 - val_loss: 1.0447 - val_accuracy: 0.6562\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 24s 2s/step - loss: 1.1653 - accuracy: 0.5429 - val_loss: 1.1697 - val_accuracy: 0.5312\n"
          ]
        }
      ]
    }
  ]
}